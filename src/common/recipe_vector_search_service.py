import time
import math
import psycopg2
from psycopg2 import Error
from psycopg2.extensions import connection
from typing import Optional, List, Tuple, Dict, Any

from .database_config import DatabaseConfig


class RecipeVectorSearchService:
    """ãƒ¬ã‚·ãƒ”ãƒ™ã‚¯ã‚¿ãƒ¼æ¤œç´¢ã‚µãƒ¼ãƒ“ã‚¹ã‚¯ãƒ©ã‚¹ï¼ˆSRPæº–æ‹ ï¼‰"""
    
    def __init__(self, db_config: DatabaseConfig):
        """RecipeVectorSearchServiceã‚’åˆæœŸåŒ–
        
        Args:
            db_config: ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹è¨­å®šã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ
        """
        self.db_config = db_config
        self.conn: Optional[connection] = None
        self.cur = None
        self._connect()
    
    def _connect(self) -> None:
        """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«æ¥ç¶š"""
        try:
            self.conn = psycopg2.connect(**self.db_config.to_connection_params())
            self.cur = self.conn.cursor()
            print(f"Connected to database: {self.db_config}")
        except Error as e:
            print(f"Error connecting to PostgreSQL: {e}")
            raise
    
    def semantic_search_recipes(self, query_embedding: List[float], search_type: str = 'combined', 
                              limit: int = 5, similarity_threshold: float = 0.0) -> List[Tuple]:
        """æ„å‘³çš„é¡ä¼¼æ€§ã«ã‚ˆã‚‹ãƒ¬ã‚·ãƒ”æ¤œç´¢
        
        Args:
            query_embedding: ã‚¯ã‚¨ãƒªã®åŸ‹ã‚è¾¼ã¿ãƒ™ã‚¯ã‚¿ãƒ¼
            search_type: æ¤œç´¢å¯¾è±¡ ('description', 'ingredients', 'instructions', 'combined')
            limit: æ¤œç´¢çµæœæ•°ã®ä¸Šé™
            similarity_threshold: é¡ä¼¼åº¦ã®æœ€å°é–¾å€¤
            
        Returns:
            (recipe_id, recipe_name, similarity_score, matched_text, description)ã®ã‚¿ãƒ—ãƒ«ãƒªã‚¹ãƒˆ
        """
        start_time = time.time()
        
        try:
            # æ¤œç´¢ã‚¿ã‚¤ãƒ—ã«å¿œã˜ã¦ã‚«ãƒ©ãƒ ã‚’é¸æŠ
            embedding_column = f"{search_type}_embedding"
            text_column = f"{search_type}_text"
            
            # ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦æ¤œç´¢ã‚¯ã‚¨ãƒª
            search_query = f"""
            SELECT 
                rv.recipe_id,
                r.name as recipe_name,
                1 - (rv.{embedding_column} <=> %s::vector) as similarity_score,
                rv.{text_column} as matched_text,
                r.description
            FROM edo_recipe_vectors rv
            JOIN edo_recipes r ON rv.recipe_id = r.id
            WHERE rv.{embedding_column} IS NOT NULL
            AND (1 - (rv.{embedding_column} <=> %s::vector)) >= %s
            ORDER BY rv.{embedding_column} <=> %s::vector
            LIMIT %s;
            """
            
            # ã‚¯ã‚¨ãƒªå®Ÿè¡Œ
            embedding_str = f"[{','.join(map(str, query_embedding))}]"
            self.cur.execute(search_query, (embedding_str, embedding_str, similarity_threshold, embedding_str, limit))
            
            results = self.cur.fetchall()
            execution_time = (time.time() - start_time) * 1000  # ms
            
            # æ¤œç´¢ãƒ­ã‚°ã‚’è¨˜éŒ²
            self._log_search_query("", query_embedding, search_type, limit, similarity_threshold, 
                                 len(results), execution_time)
            
            return results
            
        except Error as e:
            print(f"Error in semantic search: {e}")
            return []
    
    def find_similar_recipes(self, recipe_id: int, search_type: str = 'combined', 
                           limit: int = 5, exclude_self: bool = True) -> List[Tuple]:
        """æŒ‡å®šãƒ¬ã‚·ãƒ”ã«é¡ä¼¼ã™ã‚‹ãƒ¬ã‚·ãƒ”ã‚’æ¤œç´¢
        
        Args:
            recipe_id: åŸºæº–ã¨ãªã‚‹ãƒ¬ã‚·ãƒ”ID
            search_type: æ¤œç´¢å¯¾è±¡ã‚¿ã‚¤ãƒ—
            limit: æ¤œç´¢çµæœæ•°ã®ä¸Šé™
            exclude_self: è‡ªåˆ†è‡ªèº«ã‚’çµæœã‹ã‚‰é™¤å¤–ã™ã‚‹ã‹ã©ã†ã‹
            
        Returns:
            (recipe_id, recipe_name, similarity_score, matched_text)ã®ã‚¿ãƒ—ãƒ«ãƒªã‚¹ãƒˆ
        """
        try:
            # åŸºæº–ãƒ¬ã‚·ãƒ”ã®åŸ‹ã‚è¾¼ã¿ã‚’å–å¾—
            embedding_column = f"{search_type}_embedding"
            text_column = f"{search_type}_text"
            
            get_embedding_query = f"""
            SELECT {embedding_column}
            FROM edo_recipe_vectors
            WHERE recipe_id = %s AND {embedding_column} IS NOT NULL;
            """
            
            self.cur.execute(get_embedding_query, (recipe_id,))
            result = self.cur.fetchone()
            
            if not result:
                print(f"ãƒ¬ã‚·ãƒ”ID {recipe_id} ã®åŸ‹ã‚è¾¼ã¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                return []
            
            base_embedding = result[0]
            
            # é¡ä¼¼ãƒ¬ã‚·ãƒ”æ¤œç´¢
            exclusion_clause = "AND rv.recipe_id != %s" if exclude_self else ""
            
            similar_query = f"""
            SELECT 
                rv.recipe_id,
                r.name as recipe_name,
                1 - (rv.{embedding_column} <=> %s::vector) as similarity_score,
                rv.{text_column} as matched_text
            FROM edo_recipe_vectors rv
            JOIN edo_recipes r ON rv.recipe_id = r.id
            WHERE rv.{embedding_column} IS NOT NULL
            {exclusion_clause}
            ORDER BY rv.{embedding_column} <=> %s::vector
            LIMIT %s;
            """
            
            params = [base_embedding, base_embedding, limit]
            if exclude_self:
                params.insert(-2, recipe_id)  # é™¤å¤–ã™ã‚‹recipe_idã‚’è¿½åŠ 
            
            self.cur.execute(similar_query, params)
            return self.cur.fetchall()
            
        except Error as e:
            print(f"Error finding similar recipes: {e}")
            return []
    
    def hybrid_search(self, query_text: str, query_embedding: List[float], 
                     keyword_weight: float = 0.3, vector_weight: float = 0.7,
                     limit: int = 5) -> List[Tuple]:
        """ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œç´¢ã¨ãƒ™ã‚¯ã‚¿ãƒ¼æ¤œç´¢ã‚’çµ„ã¿åˆã‚ã›ãŸãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰æ¤œç´¢
        
        Args:
            query_text: æ¤œç´¢ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
            query_embedding: ã‚¯ã‚¨ãƒªã®åŸ‹ã‚è¾¼ã¿ãƒ™ã‚¯ã‚¿ãƒ¼
            keyword_weight: ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œç´¢ã®é‡ã¿
            vector_weight: ãƒ™ã‚¯ã‚¿ãƒ¼æ¤œç´¢ã®é‡ã¿
            limit: æ¤œç´¢çµæœæ•°ã®ä¸Šé™
            
        Returns:
            (recipe_id, recipe_name, hybrid_score, keyword_score, vector_score)ã®ã‚¿ãƒ—ãƒ«ãƒªã‚¹ãƒˆ
        """
        try:
            # ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰æ¤œç´¢ã‚¯ã‚¨ãƒªï¼ˆpg_bigmã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œç´¢ + ãƒ™ã‚¯ã‚¿ãƒ¼æ¤œç´¢ï¼‰
            hybrid_query = """
            WITH keyword_scores AS (
                SELECT 
                    rv.recipe_id,
                    r.name,
                    GREATEST(
                        COALESCE(bigm_similarity(r.name, %s), 0),
                        COALESCE(bigm_similarity(r.description, %s), 0),
                        COALESCE(bigm_similarity(rv.combined_text, %s), 0)
                    ) as keyword_score
                FROM edo_recipe_vectors rv
                JOIN edo_recipes r ON rv.recipe_id = r.id
                WHERE rv.combined_embedding IS NOT NULL
            ),
            vector_scores AS (
                SELECT 
                    rv.recipe_id,
                    r.name,
                    1 - (rv.combined_embedding <=> %s::vector) as vector_score
                FROM edo_recipe_vectors rv
                JOIN edo_recipes r ON rv.recipe_id = r.id
                WHERE rv.combined_embedding IS NOT NULL
            )
            SELECT 
                ks.recipe_id,
                ks.name as recipe_name,
                (%s * ks.keyword_score + %s * vs.vector_score) as hybrid_score,
                ks.keyword_score,
                vs.vector_score
            FROM keyword_scores ks
            JOIN vector_scores vs ON ks.recipe_id = vs.recipe_id
            WHERE ks.keyword_score > 0.0 OR vs.vector_score > 0.3
            ORDER BY hybrid_score DESC
            LIMIT %s;
            """
            
            embedding_str = f"[{','.join(map(str, query_embedding))}]"
            self.cur.execute(hybrid_query, (
                query_text, query_text, query_text,  # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œç´¢ç”¨
                embedding_str,  # ãƒ™ã‚¯ã‚¿ãƒ¼æ¤œç´¢ç”¨
                keyword_weight, vector_weight,  # é‡ã¿
                limit
            ))
            
            return self.cur.fetchall()
            
        except Error as e:
            print(f"Error in hybrid search: {e}")
            return []
    
    def get_recipe_details_with_vectors(self, recipe_id: int) -> Optional[Dict[str, Any]]:
        """ãƒ¬ã‚·ãƒ”ã®è©³ç´°æƒ…å ±ã‚’ãƒ™ã‚¯ã‚¿ãƒ¼ãƒ‡ãƒ¼ã‚¿ã¨å…±ã«å–å¾—
        
        Args:
            recipe_id: ãƒ¬ã‚·ãƒ”ID
            
        Returns:
            ãƒ¬ã‚·ãƒ”è©³ç´°è¾æ›¸ã€å¤±æ•—æ™‚ã¯None
        """
        try:
            detail_query = """
            SELECT 
                r.id, r.name, r.url, r.description, r.tips,
                rv.description_text, rv.ingredients_text, rv.instructions_text, rv.combined_text,
                rv.embedding_model, rv.created_at as vector_created_at
            FROM edo_recipes r
            LEFT JOIN edo_recipe_vectors rv ON r.id = rv.recipe_id
            WHERE r.id = %s;
            """
            
            self.cur.execute(detail_query, (recipe_id,))
            result = self.cur.fetchone()
            
            if not result:
                return None
            
            # ææ–™ã¨æ‰‹é †ã‚’å–å¾—
            ingredients_query = """
            SELECT ingredient FROM recipe_ingredients 
            WHERE recipe_id = %s ORDER BY sort_order;
            """
            
            instructions_query = """
            SELECT instruction FROM recipe_instructions 
            WHERE recipe_id = %s AND instruction_type = 'modern'
            ORDER BY step_number;
            """
            
            self.cur.execute(ingredients_query, (recipe_id,))
            ingredients = [row[0] for row in self.cur.fetchall()]
            
            self.cur.execute(instructions_query, (recipe_id,))
            instructions = [row[0] for row in self.cur.fetchall()]
            
            return {
                "id": result[0],
                "name": result[1],
                "url": result[2],
                "description": result[3],
                "tips": result[4],
                "ingredients": ingredients,
                "instructions": instructions,
                "vector_data": {
                    "description_text": result[5],
                    "ingredients_text": result[6],
                    "instructions_text": result[7],
                    "combined_text": result[8],
                    "embedding_model": result[9],
                    "vector_created_at": result[10]
                } if result[5] else None
            }
            
        except Error as e:
            print(f"Error getting recipe details: {e}")
            return None
    
    def calculate_recipe_similarities(self, limit_pairs: int = 100) -> bool:
        """ãƒ¬ã‚·ãƒ”é–“ã®é¡ä¼¼æ€§ã‚’äº‹å‰è¨ˆç®—ã—ã¦ãƒ†ãƒ¼ãƒ–ãƒ«ã«ä¿å­˜
        
        Args:
            limit_pairs: è¨ˆç®—ã™ã‚‹ãƒšã‚¢æ•°ã®ä¸Šé™
            
        Returns:
            è¨ˆç®—æˆåŠŸæ™‚ã¯Trueã€å¤±æ•—æ™‚ã¯False
        """
        try:
            print("ğŸ”„ ãƒ¬ã‚·ãƒ”é–“é¡ä¼¼æ€§ã®è¨ˆç®—ã‚’é–‹å§‹...")
            
            # å…¨ãƒ¬ã‚·ãƒ”ã®åŸ‹ã‚è¾¼ã¿ã‚’å–å¾—
            get_all_embeddings_query = """
            SELECT recipe_id, description_embedding, ingredients_embedding, 
                   instructions_embedding, combined_embedding
            FROM edo_recipe_vectors
            WHERE combined_embedding IS NOT NULL
            ORDER BY recipe_id;
            """
            
            self.cur.execute(get_all_embeddings_query)
            all_embeddings = self.cur.fetchall()
            
            if len(all_embeddings) < 2:
                print("âš ï¸  è¨ˆç®—ã«å¿…è¦ãªåŸ‹ã‚è¾¼ã¿ãƒ‡ãƒ¼ã‚¿ãŒä¸è¶³ã—ã¦ã„ã¾ã™")
                return False
            
            # é¡ä¼¼æ€§è¨ˆç®—ã¨DBæŒ¿å…¥
            similarity_pairs = []
            pair_count = 0
            
            for i, recipe1 in enumerate(all_embeddings):
                for j, recipe2 in enumerate(all_embeddings[i+1:], i+1):
                    if pair_count >= limit_pairs:
                        break
                    
                    # å„ã‚¿ã‚¤ãƒ—ã®é¡ä¼¼åº¦è¨ˆç®—
                    desc_sim = self._cosine_similarity(recipe1[1], recipe2[1])
                    ing_sim = self._cosine_similarity(recipe1[2], recipe2[2])
                    inst_sim = self._cosine_similarity(recipe1[3], recipe2[3])
                    comb_sim = self._cosine_similarity(recipe1[4], recipe2[4])
                    
                    similarity_pairs.append((
                        recipe1[0], recipe2[0],  # source_recipe_id, target_recipe_id
                        desc_sim, ing_sim, inst_sim, comb_sim
                    ))
                    
                    pair_count += 1
                
                if pair_count >= limit_pairs:
                    break
            
            # ãƒãƒƒãƒã§DBæŒ¿å…¥
            if similarity_pairs:
                insert_query = """
                INSERT INTO recipe_similarities 
                (source_recipe_id, target_recipe_id, description_similarity, 
                 ingredients_similarity, instructions_similarity, combined_similarity)
                VALUES (%s, %s, %s, %s, %s, %s)
                ON CONFLICT (source_recipe_id, target_recipe_id) 
                DO UPDATE SET
                    description_similarity = EXCLUDED.description_similarity,
                    ingredients_similarity = EXCLUDED.ingredients_similarity,
                    instructions_similarity = EXCLUDED.instructions_similarity,
                    combined_similarity = EXCLUDED.combined_similarity;
                """
                
                self.cur.executemany(insert_query, similarity_pairs)
                self.conn.commit()
                
                print(f"âœ“ {len(similarity_pairs)}ãƒšã‚¢ã®é¡ä¼¼æ€§ã‚’è¨ˆç®—ãƒ»ä¿å­˜ã—ã¾ã—ãŸ")
                return True
            else:
                print("âš ï¸  è¨ˆç®—å¯èƒ½ãªãƒšã‚¢ãŒã‚ã‚Šã¾ã›ã‚“")
                return False
                
        except Error as e:
            print(f"Error calculating similarities: {e}")
            self.conn.rollback()
            return False
    
    def get_search_logs(self, limit: int = 50) -> List[Tuple]:
        """æ¤œç´¢ãƒ­ã‚°ã‚’å–å¾—
        
        Args:
            limit: å–å¾—ã™ã‚‹ãƒ­ã‚°æ•°ã®ä¸Šé™
            
        Returns:
            æ¤œç´¢ãƒ­ã‚°ã®ã‚¿ãƒ—ãƒ«ãƒªã‚¹ãƒˆ
        """
        try:
            log_query = """
            SELECT query_text, search_type, result_count, max_similarity, 
                   avg_similarity, execution_time_ms, created_at
            FROM vector_search_logs
            ORDER BY created_at DESC
            LIMIT %s;
            """
            
            self.cur.execute(log_query, (limit,))
            return self.cur.fetchall()
            
        except Error as e:
            print(f"Error getting search logs: {e}")
            return []
    
    def _cosine_similarity(self, vec1, vec2) -> float:
        """ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦ã‚’è¨ˆç®—
        
        Args:
            vec1: ãƒ™ã‚¯ã‚¿ãƒ¼1ï¼ˆList[float]ã¾ãŸã¯PostgreSQL vectorå‹æ–‡å­—åˆ—ï¼‰
            vec2: ãƒ™ã‚¯ã‚¿ãƒ¼2ï¼ˆList[float]ã¾ãŸã¯PostgreSQL vectorå‹æ–‡å­—åˆ—ï¼‰
            
        Returns:
            ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦ (0.0-1.0)
        """
        # PostgreSQL vectorå‹ã‹ã‚‰ Python listã«å¤‰æ›
        v1 = self._parse_vector(vec1)
        v2 = self._parse_vector(vec2)
        
        if not v1 or not v2 or len(v1) != len(v2):
            return 0.0
        
        dot_product = sum(a * b for a, b in zip(v1, v2))
        norm1 = math.sqrt(sum(a * a for a in v1))
        norm2 = math.sqrt(sum(b * b for b in v2))
        
        if norm1 == 0 or norm2 == 0:
            return 0.0
        
        return dot_product / (norm1 * norm2)
    
    def _parse_vector(self, vector_data) -> List[float]:
        """PostgreSQL vectorå‹ãƒ‡ãƒ¼ã‚¿ã‚’Python listã«å¤‰æ›
        
        Args:
            vector_data: PostgreSQL vectorå‹ãƒ‡ãƒ¼ã‚¿ï¼ˆæ–‡å­—åˆ—ã¾ãŸã¯ãƒªã‚¹ãƒˆï¼‰
            
        Returns:
            floatå€¤ã®ãƒªã‚¹ãƒˆ
        """
        if vector_data is None:
            return []
        
        # æ—¢ã«ãƒªã‚¹ãƒˆã®å ´åˆã¯ãã®ã¾ã¾è¿”ã™
        if isinstance(vector_data, list):
            return [float(x) for x in vector_data]
        
        # æ–‡å­—åˆ—ã®å ´åˆã¯ãƒ‘ãƒ¼ã‚¹
        if isinstance(vector_data, str):
            # PostgreSQL vectorå‹ã¯ "[1.0,2.0,3.0]" å½¢å¼
            vector_str = vector_data.strip()
            if vector_str.startswith('[') and vector_str.endswith(']'):
                vector_str = vector_str[1:-1]  # è§’æ‹¬å¼§ã‚’é™¤å»
            
            try:
                return [float(x.strip()) for x in vector_str.split(',') if x.strip()]
            except (ValueError, AttributeError):
                print(f"Warning: Failed to parse vector data: {vector_data}")
                return []
        
        # ãã®ä»–ã®å‹ï¼ˆãƒ¡ãƒ¢ãƒªãƒ“ãƒ¥ãƒ¼ãªã©ï¼‰
        try:
            return [float(x) for x in vector_data]
        except (TypeError, ValueError):
            print(f"Warning: Unsupported vector data type: {type(vector_data)}")
            return []
    
    def _log_search_query(self, query_text: str, query_embedding: List[float], 
                         search_type: str, limit_count: int, similarity_threshold: float,
                         result_count: int, execution_time_ms: float) -> None:
        """æ¤œç´¢ã‚¯ã‚¨ãƒªã‚’ãƒ­ã‚°ã«è¨˜éŒ²
        
        Args:
            query_text: æ¤œç´¢ãƒ†ã‚­ã‚¹ãƒˆ
            query_embedding: ã‚¯ã‚¨ãƒªåŸ‹ã‚è¾¼ã¿
            search_type: æ¤œç´¢ã‚¿ã‚¤ãƒ—
            limit_count: çµæœæ•°åˆ¶é™
            similarity_threshold: é¡ä¼¼åº¦é–¾å€¤
            result_count: å®Ÿéš›ã®çµæœæ•°
            execution_time_ms: å®Ÿè¡Œæ™‚é–“ï¼ˆãƒŸãƒªç§’ï¼‰
        """
        try:
            # çµæœã®çµ±è¨ˆè¨ˆç®—ï¼ˆç°¡æ˜“ç‰ˆï¼‰
            max_similarity = 1.0 if result_count > 0 else 0.0
            min_similarity = similarity_threshold
            avg_similarity = (max_similarity + min_similarity) / 2
            
            embedding_str = f"[{','.join(map(str, query_embedding))}]" if query_embedding else None
            
            log_query = """
            INSERT INTO vector_search_logs 
            (query_text, query_embedding, search_type, limit_count, similarity_threshold,
             result_count, max_similarity, min_similarity, avg_similarity, execution_time_ms)
            VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s);
            """
            
            self.cur.execute(log_query, (
                query_text, embedding_str, search_type, limit_count, similarity_threshold,
                result_count, max_similarity, min_similarity, avg_similarity, execution_time_ms
            ))
            self.conn.commit()
            
        except Error:
            # ãƒ­ã‚°è¨˜éŒ²å¤±æ•—ã¯æ¤œç´¢æ©Ÿèƒ½ã«å½±éŸ¿ã—ãªã„ã‚ˆã†ã«ã‚µã‚¤ãƒ¬ãƒ³ãƒˆ
            pass
    
    def close(self) -> None:
        """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šã‚’é©åˆ‡ã«ã‚¯ãƒ­ãƒ¼ã‚º"""
        if self.cur:
            self.cur.close()
        if self.conn:
            self.conn.close()
    
    def __enter__(self):
        """ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ã®ã‚¨ãƒ³ãƒˆãƒªãƒ¼"""
        return self
    
    def __exit__(self, exc_type, exc_val, exc_tb):
        """ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ã®ã‚¤ã‚°ã‚¸ãƒƒãƒˆ"""
        self.close()
    
    def __del__(self):
        """ãƒ‡ã‚¹ãƒˆãƒ©ã‚¯ã‚¿: ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šã‚’é©åˆ‡ã«ã‚¯ãƒ­ãƒ¼ã‚º"""
        self.close()